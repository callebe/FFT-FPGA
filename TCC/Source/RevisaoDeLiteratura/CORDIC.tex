
\label{section:Cordic}
Na equação (\ref{eq:Xr}) nota-se que o calculo a FFT depende essencialmente de um multiplicação complexa entre $W_{N_0}^r$ e $H_r$, onde $H_r$ representa um vetor complexo qualquer, e $W_{N_0}^r$ é igual a $e^{\frac{2\pi r}{N_0}}$. Esta tarefa pode ser realizada através da representação de $W_{N_0}^r$ e $H_r$ na forma retangular, considerando para efeitos de exemplo $W_{N_0}^r ~=~x+iy$ e $H_r~=~a+ib$, logo:

\begin{eqnarray}
	W_{N_0}^r ~=~x+iy \\
	H_r~=~a+ib \\
	H_r \cdot W_{N_0}^r~=~(x+iy)(a+ib) \\
	H_r \cdot W_{N_0}^r~=~(xa-yb)+i(xb+ya) 
\end{eqnarray}

Desta forma serão necessários utilizar 4 multiplicadores e 2 somadores, para completar esta operação \cite[p.~1]{alvin}. Porém em termos de complexidade hardware, multiplicadores são mais elaborados e em muitos dispositivos FPGA possuem apenas algumas dezenas, o que limita a utilização de multiplicadores em paralelo, reduzindo a velocidade de calculo da FFT.

Para contornar o problema considere expressar o vetor $H_r$ na forma polar $re^{\theta_r}$ e manter $W_{N_0}^r$ igual a $e^{\frac{2\pi r}{N_0}}$, logo:

\begin{eqnarray}
	H_r~=~Re^{\left(\theta_r\right)} \\
	H_r \cdot W_{N_0}^r~=~re^{\left(\theta_r\right)} \cdot e^{\left(\frac{2\pi r}{N_0}\right)} \\
	H_r \cdot W_{N_0}^r~=re^{\left(\theta_r+\frac{2\pi r}{N_0}\right)}
\end{eqnarray}

Assim $H_r \cdot W_{N_0}^r$ é equivalente a operação trigonométrica de rotacionar o vetor complexo $H_r$ pelo ângulo de $2\pi r/N_0$. Como mostrado na Figura (\ref{fig:RotacaoVetorA0}) 

\vspace{6mm}
\begin{figure}[H]
	\centering
	\captionsetup{width=0.5\textwidth, font=footnotesize, textfont=bf}	
	\includegraphics[width=0.5\linewidth]{Images/RevisaoDeLiteratura/RotacaoVetorA0.eps}
	\caption{Rotação de $H_r$ pelo ângulo de $2\pi r/N_0$}
	\vspace{-3.5mm}
	\caption*{Fonte: Autoria Própria}
	\label{fig:RotacaoVetorA0}
\end{figure}
\vspace{6mm}

Implementar operações trigonométricas sem utilizar multiplicadores, para evitar o gargalo que eles possam provocar, parece difícil, porém existe uma técnica bastante usada no desenvolvimento de circuitos lógicos em FPGA que o possibilita. Com o objetivo de oferecer uma solução para o calculo de funções trigonométricas mais simples, utilizando o mínimo de recursos de tempo e \textit{hardware}, Jack E. Volder\cite{Volder} desenvolveu a técnica de computação trigonométrica CORDIC (\textit{COordinate Rotation DIgital Computer}).


\subsection{CORDIC Tradicional}
\label{sec:CoricTradicional}

O algoritmo CORDIC tem como base as micro-rotações do vetor alvo, de tal modo que cada micro-rotação possa ser feita por somas e deslocamentos de bits. Para tal considere o vetor $H_r ~ = ~x~+~iy$, e a matriz de rotação $A$ em função do angulo $\theta$. A rotação do vetor é dada  pela equação (\ref{eq:rotacaoVetorial})\cite{Garrido}.

\begin{equation}
	\left[\begin{array}{c}
	x' \\ 
	y' \\ 
	\end{array}\right] = \left[\begin{array}{cc}
	cos(\theta) & -sin(\theta)\\ 
	sin(\theta) & cos(\theta) \\ 
	\end{array}\right] \left[\begin{array}{c}
	x \\ 
	y \\ 
	\end{array}\right]
	\label{eq:rotacaoVetorial}
\end{equation}
   
  
Isolando o termo $cos( \theta )$ da equação (\ref{eq:rotacaoVetorial}), é obtido o sistema (\ref{eq:rotacaoVetorialB}), o qual é a base da técnica CORDIC convencional \cite{Motaz}.

\begin{equation}
	\left[\begin{array}{c}
	x' \\ 
	y' \\ 
	\end{array}\right] = cos(\theta) \left[\begin{array}{cc}
	1 & -tan(\theta)\\ 
	tan(\theta) & 1 \\ 
	\end{array}\right] \left[\begin{array}{c}
	x \\ 
	y \\ 
	\end{array}\right]
	\label{eq:rotacaoVetorialB}
\end{equation}

Segundo \cite{Volder}, ao invés de rotacionar completamente o vetor $H_r$ pelo angulo $\theta$, ou pelo angulo $2\pi r/N_0$ como  mostrado na Figura (\ref{fig:RotacaoVetorA0}),  o algoritmo CORDIC rotaciona $H_r$ por ângulos $\theta_n$ muito menores, sendo estes frações de $\theta$ de tal forma que:

\begin{equation}
	\theta ~=~ \sum_{n = 0}^{N-1} \mu_n \theta_n + \zeta
	\label{eq:aproximation}
\end{equation}

onde e $\mu_n$ representa o sentido da micro rotação $\theta_n$, se ela for no sentido horário é igual a 1, caso contrário é igual a -1. E $\zeta$ é o erro acumulado da aproximação pelo somatório, aqui este será considerado suficientemente pequeno para ser ignorado. O primeiro ponto dessa abordagem é o fato de que se um angulo $\theta_n$ for suficientemente pequeno é possível afirmar que:

\begin{equation}
	\theta_n~\simeq~tan^{-1} \theta_n
	\label{eq:AproximacaoThetaTan}
\end{equation}
 
Assim é possível substituir $\theta$ no sistema da Equação (\ref{eq:rotacaoVetorialB}), e  obter a seguinte expressão:

\begin{equation}
	\left[\begin{array}{c}
	x' \\ 
	y' \\ 
	\end{array}\right] = cos(tan^{-1} \theta_n) \left[\begin{array}{cc}
	1 & -tan(tan^{-1} \theta_n)\\ 
	tan(tan^{-1} \theta_n) & 1 \\ 
	\end{array}\right] \left[\begin{array}{c}
	x \\ 
	y \\ 
	\end{array}\right]
	\label{eq:rotacaoVetorialC}
\end{equation}

O segundo ponto é que para satisfazer a Equação (\ref{eq:aproximation}) so é necessário que a soma do conjunto de micro rotações $\theta_n$ resulte no angulo $\theta$, o que abre a possibilidade de se escolher um conjunto de micro rotações baseadas em deslocamento de bits, como:

\begin{equation}
	\theta_n ~=~ tan^{-1} 2^{-n}
	\label{eq:EquivalenciaThetaTan}
\end{equation}

Logo aplicando a Equação(\ref{eq:EquivalenciaThetaTan}) em (\ref{eq:rotacaoVetorialC}), é obtido a expressão final para CORDIC:

\begin{equation}
	\left[\begin{array}{c}
	x' \\ 
	y' \\ 
	\end{array}\right] = \prod_{n=0}^{N-1} K_c \left[\begin{array}{cc}
	1 & -\mu 2^{-n}\\ 
	\mu 2^{-n} & 1 \\ 
	\end{array}\right] \left[\begin{array}{c}
	x \\ 
	y \\ 
	\end{array}\right]
	\label{eq:rotacaoVetorialD}
\end{equation}

\begin{equation}
	k_c = cos(tan^{-1} (2^{-n})) = \frac{1}{\sqrt{1 + 2^{-2n}}}
	\label{eq:K}
\end{equation}

onde

\begin{equation}
	\mu \in \{-1,1\} 
\end{equation}

$K_c$  é calculado a cada micro-rotação $n$, assim seu valor total é dado pelo produto de todos os $N$ ganhos.  O número total de micro-rotações ($N$) é escolhido de acordo com o SQNR  (\textit{Signal-to-Quantization-Noise Ratio }) admissível a cada rotação. Segundo \cite{Volder}, considerando $N\rightarrow\infty$, $K_c$ é passa a ser constate e aproximadamente igual a $0,6073$. O inverso de $K_c$ é igual a $1,647$, sendo conhecido como "Ganho CORDIC". Tal ganho é independe do angulo a ser rotacionado, e em muitos sistemas este ganho é só compensado fora do bloco lógico de cálculo do CORDIC.

Como pode ser observado o algoritmo CORDIC se resume a operações de deslocamento de \textit{bit} e somas. A direção das micro-rotações é determinada por $\mu$, que depende diretamente sinal do ângulo $\theta_n$ a se rotacionar. Em aplicações onde o ângulo a se rotacionar é previamente conhecido, que é o caso da FFT,  as sequências de rotações $\mu$ podem ser armazenado em uma ROM \cite{Motaz}. Tornando as micro-rotações como $n$ interações, armazenando em $z$ os ângulos rotacionados a cada interação de $\theta_n$, o algoritmo CORDIC é dado por:

\begin{eqnarray}
	x(n+1) = x(n) - [\mu 2^{-n}]y(n) \\
	y(n+1) = y(n) + [\mu 2^{-n}]x(n) \\
	z(n+1) = z(n)-tan^{-1} [\mu 2^{-n}] \\
	\label{eq:CORDIC}
\end{eqnarray}

Onde:

\begin{eqnarray}
	H_r~=~x(0)+iy(0)\\
	\theta ~=~z(0) \\
	n~=~\left\{0, 1, ..., N-1\right\} \\
	\mu~=
	\begin{bmatrix}
		1 & z \left(n \right) \geq 0  \\
		-1 & z \left(n \right) < 0 
	\end{bmatrix}
	\label{eq:CORDICRules}
\end{eqnarray}


\subsection{EEAS-CORDIC}

No algoritmo CORDIC cada ângulo de rotação $\theta_n$ é necessariamente determinado de maneira sequencial após cada interação $n$, através de conjunto de ângulos elementares definidos como:

\begin{eqnarray}
	S_1 = \{ tan^{-1} ( \mu 2^{-n} ) \} \\
	:~\mu \in \{-1,1\},~n\in \{0,1, \dots, N-1\} 
	\label{eq:s0}
\end{eqnarray}

A partir do ângulo inicial de $H_r$, o algoritmo Cordic realiza as $N$ interações deslocando o vetor através do conjunto de ângulos elementares, de forma a reduzir a diferença entre o angulo atual e o ângulo. Para fins de comparação a  Figura (\ref{fig:CordicComparationCordic}) apresenta a densidade combinacional dentro do circulo unitário do conjunto de ângulos elementares do Algoritmo CORDIC tradicional.

\vspace{5mm}
\begin{figure}[H]
	\centering
	\captionsetup{width=0.6\textwidth, font=footnotesize, textfont=bf}	
	\includegraphics[width=0.6\linewidth]{Images/RevisaoDeLiteratura/CordicComparationCordic.PNG}
	\caption{Ângulos Elementares - Cordic Tradicional com N=4  \\ Fonte: }
	\vspace{-3.5mm}
	\caption*{Fonte: \cite{Chih}}
	\label{fig:CordicComparationCordic}
\end{figure} 
\vspace{5mm}

Segundo \citeonline{Shing} o maior problema do CORDIC é a baixa velocidade computacional de calculo deste algoritmo, devido principalmente a necessidade de um grade  número de interações $N$ para atingir um erro de aproximação $\zeta$ aceitável. O error de aproximação $\zeta$ é dado por:

\begin{equation}
	\zeta = \left| \theta~-~\sum_{n=0}^{N-1} \mu \theta_n \right| ~ =~ \left| \theta~-~\sum_{n=0}^{N-1}  \mu ~ tan^{-1} (2^{-n}) \right| 
	\label{eq:erroTheta}
\end{equation} 

Onde:

\begin{equation}
\mu \in \{-1,~0,~1\}
\end{equation} 

Em aplicações onde os ângulos de rotação são conhecidos é possível relaxar as restrições da Equação (\ref{fig:CordicComparationCordic}), através do método \textit{Angle Recoding} (AR) \cite{Shing}. Os AR tem como objetivo reduzir o número de interações CORDIC e  o erro $~\zeta~$, para tal o AR que expande o conjunto de combinações lineares da Equação (\ref{eq:s0}) adicionando zero ao conjunto de $\mu$.  Obtendo assim uma melhor aproximação para certos valores de $\theta$ e uma redução de até 50\% no número de interações \cite{Meher}. 

Por outro lado o método \textit{Extended Elementary-Angle-Set Recoding} (EEASR) apresenta um método baseado no AR que, além de expandir o conjunto de $\mu$, estende também o conjunto de ângulos elementares (\textit{Elementary-Angle-Set}, EAS), para aumentar a possibilidades de decomposição do ângulo de rotação\cite{Cheng}. Para perceber a modificação que o EEASR propõem nota-se primeiramente que o conjunto de ângulos elementares no CORDIC utilizando AR é definido como:

\begin{eqnarray}
	S_1 = \{ tan^{-1} ( \mu 2^{-s} ) \} \\
	:~\mu \in \{-1,0,1\},~s\in \{0,1, \dots, N-1\} 
	\label{eq:s1}
 \end{eqnarray}    
 
Como é possível notar em (\ref{eq:s1}) os ângulos elementares dependem de apenas um termo potência de dois, ou \textit{Signed Power of Two} (SPT). Segundo \cite{Cheng} para aumentar a precisão dos ângulos elementares e consequentemente reduzir o numero de interações pode-se adicionar mais um termo SPT em  (\ref{eq:s1}). Assim,
  
\begin{eqnarray}
	 S_2 = \{ tan^{-1} ( \mu_{0} 2^{-s_0} + \mu_{1} 2^{-s_1}) \} \\ 
    :~\mu_{0},\mu_{1} \in \{-1,0,1\},~s_0,s_1 \in \{0,1, \dots, S\} 
    \label{eq:S2}
\end{eqnarray} 

Onde $S$ é denominado como o número máximo de deslocamentos de \textit{bits} a direita que podem ser realizados. Este valor esta diretamente relacionado com o quantidade de \textit{bits} utilizados para representar um número dentro da arquitetura onde o Cordic é implementado. Por exemplo em uma aplicação em FPGA, onde a palavra binária utilizada para representar um número inteiro tenha apenas 16 \textit{bits}, não faz sentido o valor de $S$ ser maior do 15.

Portanto alterando a equação (\ref{eq:rotacaoVetorialC}) com base em  (\ref{eq:S2}) é obtido a expressão para calculo interativo CORDIC utilizando o EEASR:


\begin{eqnarray}
	\left[\begin{array}{c}
	x(n+1) \\
	y(n+1) \\
	\end{array}\right]
	\left[\begin{array}{cc}
	1 & \mu_{0}2^{-s_0 (n)} + \mu_{1}2^{-s_1 (n)} \\
	\mu_{0}2^{-s_0 (n)} + \mu_{1}2^{-s_1 (n)} & 1 \\
	\end{array}\right] \left[\begin{array}{c}
	x(n) \\
	y(n) \\
	\end{array}	\right]\\
	:~\mu_{i},\mu_{j} \in \{-1,0,1\},~s_0,s_1 \in \{0,1, \dots, S\}
	\label{eq:EEASR}
\end{eqnarray}

\begin{equation}
	\theta_n~=~tan^{-1} \left(\mu_{0}2^{-s_0 (n)} + \mu_{1}2^{-s_1 (n)} \right)
	\label{eq:EEASRtheta}
\end{equation}

\begin{equation}
	z(n+1)~=~z(n-1)+\theta_n
\label{eq:EEASRSync}
\end{equation}


É importante notar que ao adicionar mais termos a $S_1$, o ganho $K_c$ também é modificado passando a ser definido por:

\begin{equation}
	K_n~=~\frac{1}{\sqrt{1+ [\mu_{0}2^{-s_0 (n)} + \mu_{1}2^{-s_1 (n)}]^2}}
	\label{eq:EEASRKcn}
\end{equation}

Com a alteração de $K_c$ o ganho passa a não ser mais constante, e varia de acordo com cada interação $N$. Sendo assim necessário calcular o ganho $K_c$ para cada interação afim de realizar a compensação. O valor de $K_c$ ao final de cada operação de calculo CORDIC passa a ser definido por: 

\begin{equation}
	K_c~=~\prod_{n=0}^{N-1} K_n
	\label{eq:EEASRKc}
\end{equation}

Para casos em que o angulo $\theta$ a ser rotacionado é conhecido, como é o caso da FFT, é possível escolher previamente o conjunto de valores $\mu_{0}$, $\mu_{1}$, $s_{0}$ e $s_{1}$, e consequentemente através da Equação (\ref{eq:EEASRKcn}) determinar o valor de $K_c$ a ser compensado a cada interação, e consequentemente por meio de  (\ref{eq:EEASRKc}) determinar a compensação de $K_c$ a ser realizada após cada operação de rotação. Para tal é realizado, após as interações de rotação do algoritmo, uma correção no módulo do vetor resultante por meio da seguinte operação de rotação modificada:

\begin{eqnarray}
	x(n+1) = x(n) - [\mu_{0}2^{-s_0 (n)} + \mu_{1}2^{-s_1 (n)}]x(n) \\
	y(n+1) = y(n) - [\mu_{0}2^{-s_0 (n)} + \mu_{1}2^{-s_1 (n)}]y(n) \\
	z(n+1) = z(n) 
	\label{eq:EEASRKcCorrection}
\end{eqnarray}

Onde $\mu_{0}$, $\mu_{1}$, $s_{0}$ e $s_{1}$ para esta operação são escolhidos de modo a minimizar o erro de compensação de $K_c$. 

Com a relaxação das restrições introduzidas pelo método AR e pelo EEASR, a densidade combinacional dentro do circulo unitário do conjunto de ângulos elementares do Algoritmo CORDIC aumenta, se comparado ao CORDIC tradicional, como pode ser visto na Figura (\ref{fig:CordicComparationEEAS}). 

\vspace{5mm}
\begin{figure}[H]
	\centering
	\captionsetup{width=0.6\textwidth, font=footnotesize, textfont=bf}	
	\includegraphics[width=0.6\linewidth]{Images/RevisaoDeLiteratura/CordicComparationEEAS.PNG}
	\caption{EEAS com N=2 e S=4}
	\vspace{-3.5mm}
	\caption*{Fonte: \cite{Chih}}
	\label{fig:CordicComparationEEAS}
\end{figure}    
\vspace{5mm}

\subsubsection{Algoritmo TBS}
\label{section:TBS}

A relaxação das restrições feita pelos métodos AR e  EEASR tornaram o algoritmo iterativo CORDIC mais eficiente, porém ele abre uma questão crucial: a determinação dos conjuntos $\mu$ e $s$. No algoritmo CORDIC tradicional o valor de $\mu$ estava contido no conjunto $\{-1, 1\}$, e era determinado com base no sinal de $z(n)$ a cada interação, porém no método AR $\mu$ passa a estar contido no conjunto $\{-1, 0, 1\}$. Logo determinar o valor de $\mu$ a cada interação torna-se uma tarefa de otimização, em relação a minimizar o erro $\zeta$, na forma:

\begin{equation}
	min~\zeta~=~\left| \theta~-~\sum_{n=0}^{N-1}  \mu ~ tan^{-1} (2^{-n}) \right|
	\label{eq:MinZeta}
\end{equation} 

Onde:

\begin{equation}
	\mu \in \{-1,~0,~1\}
\end{equation} 

No algoritmo CORDIC convencional o conjunto dos ângulos elementares é definido por $S_1$ na Equação (\ref{eq:s0}), e a cada interação o deslocamento do vetor é feito com base  no elemento $n$ deste conjunto. O método EEASR adiciona mais um termo SPT a expressão do conjunto dos ângulos elementares $S_2$, definido na Equação (\ref{eq:S2}), o que possibilita a escolha de qualquer termo $s_0$ e $s_1$. Logo além de agregar a mesma necessidade de determinar o conjunto otimizado $\mu_0$ e $\mu_1$ de AR, o EEASR também requer a determinação do conjunto otimizado $s_0$ e $s_1$, a fim de também minimizar o erro $\zeta$. Portanto a função de minimização do erro $\epsilon$ é dada pela seguinte expressão: 

\begin{eqnarray}
	min~\zeta~=~\left| \theta~-~\sum_{n=0}^{N-1}  tan^{-1} (\mu_{0} 2^{-s_0} + \mu_{1} 2^{-s_1}) \right| \\
	:~\mu_{0},\mu_{1} \in \{-1,0,1\},~s_0,s_1 \in \{0,1, \dots, S\}
	\label{eq:MinZeta0}
\end{eqnarray} 

Para otimizar a Função (\ref{eq:MinZeta0})  é possível utilizar um variedade de algoritmos heurísticos ou não heurístico a fim de determinar um conjunto de parâmetros que minimize o erro $\zeta$, como por exemplo \textit{Dijkstra}, 'Caminhos Mínimos' ou o mais comum Algoritmo \textit{Greedy}. \citeonline{Cheng} propões um método de otimização para parâmetros EEAS chamado \textit{Trellis-Based Search}(TBS). 

A partir do numero máximo de interações $N$, do ângulo de rotação $\theta$ e de $W$, que representa numero de bits de $\theta$, o TBS emprega um método de otimização para encontrar os melhores parâmetros $s^0(n)$, $s^1(n)$, $\mu_{0}$ e $\mu_{1}$ \cite{Cheng}. \textit{TBS} é baseado no efeito que os diferentes arranjos dos ângulos elementares $S_2$ possíveis tem sobre $\zeta$. O algoritmo segue o seguintes passos:

\begin{enumerate}
	\item \textit{Inicialização:} Inicialmente é definido o vetor $r(k)$, o qual representa o conjunto de ângulos elementares presentes na Equação  (\ref{eq:MinZeta0}), obtidos através das possíveis combinação não redundantes de $\mu_{0}$, $\mu_{1}$, $s_0$ e $s_1$. Em seguida é definido a matriz $\phi(n,k)$ para ($1 \leq n \leq N$)  e ($1 \leq k \leq z(S_2)$), representando a estrutura de acumulação do algoritmo utilizada para alcançar o melhor resultado.  $N$ é o número de interações desejadas, enquanto $z(S_2)$ representa o número de elementos do vetor $r(k)$. Para então iniciar o algoritmo é $\phi(1,k)$ é preenchido com o vetor $r(k)$.
	
	\item \textit{Acumulação:} Em cada interação $n$ o algoritmo percorre os elementos $k$ do vetor $\phi(n+1,k^*)$, atribuindo a cada valor $k$  o menor resultado encontrado da expressão $\| \phi(n,k^*) + r(k) - \theta \|$. O índice $i$ varia $1 \leq i \leq N-1$, e $k$ varia de $1 \leq k \leq Z(S_2)$. 
	
	\item \textit{Determinação do Ótimo Global:} Ao final do processo de acumulação os elemento da coluna $\phi(N,)$ apresentam os resultados globais. Logo dentro desta coluna é determinado o valor que mais se aproxima de $\theta$, defini-se este como $\theta_{TBS}$.
	
	\item \textit{Determinação do Caminho Solução:} A partir do elemento $\theta_{TBS}$ da coluna $\phi(N,)$ é traçado o caminho reverso até a coluna $\phi(1,)$. A começar por $(k'=\theta_{TBS})$ e $(i=N)$ é  escolhido o valor da coluna $(i-1)$ que minimiza $\| \phi(1:z(S_2),i-1) + r(k') - \theta \|$, em seguida se atribui a $k'$ a posição $k$ do valor minimizante. Os valores $k'$ são armazenados em um vetor e representam as combinações de ângulos elementares que minimizam o erro $\epsilon$.
\end{enumerate}

Segue abaixo o pseudo-código que implementa o algoritmo TBS.
 
\vspace{3mm}
	\lstset{style=VHDL}
	\begin{lstlisting}[mathescape]
		% Inicialização
		$\displaystyle \phi(1,k)~=~r(k)$ para todo k,
		
		%Acumulação
		$\displaystyle FOR~i=1~to~N-1$
			$\displaystyle FOR~k=1~to~Z(S_2)$
				$\displaystyle \phi(i+1, k) ~=~ min \left\{ \mid \phi(i,k^*)+r(k)-\theta \mid : 1 \leq k^* \leq Z(S_2) \right\}$
			$\displaystyle END$
		$\displaystyle END$
		
		%Determinação do Ótimo Global
		$\displaystyle \theta_{TBS}~=~min \left\{ \mid \phi(R_m,k^*)-\theta \mid : 1 \leq k^* \leq Z(S_2) \right\}$
		$\displaystyle Result(N)~=~k^*$
		
		%Determinação do Caminho Solução
		$\displaystyle FOR~i=N~to~2$
			$\displaystyle Encontra~k'~tal~que~\phi(i,k^*)~=~min \left\{ \mid \phi(i-1,k')+r(k^*)-\theta \mid : 1 \leq k' \leq Z(S_2) \right\}$
			$\displaystyle k^*=k'$
			$\displaystyle Result(i-1)=k'$
		$\displaystyle END$
	\end{lstlisting}
	\label{code:PCTBS}
\vspace{3mm}


Em \cite{Cheng} o autor utiliza um exemplo base para explicar o algoritmo TBS, o qual também será usado aqui. Para este exemplo o ângulos de rotação $\theta$ será $pi/3$, o número máximo de interações será $N=4$ e a resolução de $\theta$ será de $W=~4$ bits. 

A primeira etapa do algoritmo então inicia com a definição do vetor $r(k)$, e o preenchimento da primeira coluna da matriz $\phi(1, )$, como pode ser visto na Figura (\ref{fig:TBSExempleA}). Na segunda etapa do algoritmo é realizada a acumulação, onde cada elemento das colunas 2, 3 e 4 são preenchidos com base na coluna anterior a partir da expressão $\| \phi(n,k^*) + r(k) - \theta \|$. Na Figura (\ref{fig:TBSExempleA}) o elemento $\phi(2,15) $ representa esta etapa, onde o valor do elemento $\phi(2,15)$ é definido a partir da soma do ângulo representante da linha 15 (r(15)), com o elemento da coluna 1 que minimiza o erro de aproximação do resultado desta soma com $\theta$, neste caso $\pi/3$. Este processo se estende até completar a coluna 4 da matriz $\phi$.

\vspace{5mm}
\begin{figure}[H]
	\centering
	\captionsetup{width=0.6\textwidth, font=footnotesize, textfont=bf}	
	\includegraphics[width=0.6\linewidth]{Images/RevisaoDeLiteratura/TBSExempleA.eps}
	\caption{Exemplo de execução do Algoritmo TBS}
	\vspace{-3.5mm}
	\caption*{Fonte: Autoria Própria}
	\label{fig:TBSExempleA}
\end{figure}    
\vspace{5mm}

Após a etapa de acumulação, a ultima coluna de $\phi$ apresenta os resultados globais da acumulação. Logo para determinar o valor ótimo global é escolhido na coluna  $\phi(4,)$ o valor $\theta_{TBS}$, que mais se aproxima de $\theta$ ou $\pi/3$. Após esta etapa  é iniciada a determinação do vetor $Result$, o qual deve conter o caminho solução necessário para atingir o valor de ótimo global $\theta_{TBS}$. Na Figura (\ref{fig:TBSExempleB}) é apresentado os caminhos mínimos para cada coluna da matriz  $\phi$, e consequentemente o melhor caminho encontrado pelo algoritmo.

\vspace{5mm}
\begin{figure}[H]
	\centering
	\captionsetup{width=0.6\textwidth, font=footnotesize, textfont=bf}	
	\includegraphics[width=0.6\linewidth]{Images/RevisaoDeLiteratura/TBSExempleB.eps}
	\caption{Exemplo de execução do Algoritmo TBS}
	\vspace{-3.5mm}
	\caption*{Fonte: Autoria Própria}
	\label{fig:TBSExempleB}
\end{figure}    
\vspace{5mm}

A tabela (\ref{tab:TBSExemple}) apresenta os valores encontrados para $\phi$ na execução do exemplo apresentado. Em destaque estão os valores do caminho solução,  que são armazenados em $Result$.

\vspace{5mm}
\begin{table}[h]
	\centering
	\captionsetup{width=.5\linewidth}
	\begin{tabular}{c|c|c|c|c|}
		\cline{2-5}
		& i=1                            & i=2                            & i=3                            & i=4                            \\ \hline
		\multicolumn{1}{|c|}{k=1}  & -1.1071                        & 0                              & 0.0339                         & 0                              \\ \hline
		\multicolumn{1}{|c|}{k=2}  & -0.9828                        & 0.1244                         & \cellcolor[HTML]{FD6864}0.1582 & 0.1244                         \\ \hline
		\multicolumn{1}{|c|}{k=3}  & -0.8961                        & 0.2111                         & 0.2450                         & 0.2111                         \\ \hline
		\multicolumn{1}{|c|}{k=4}  & -0.7854                        & 0.3218                         & 0.3556                         & 0.3218                         \\ \hline
		\multicolumn{1}{|c|}{k=5}  & -0.6435                        & 0.4636                         & 0.4975                         & 0.4636                         \\ \hline
		\multicolumn{1}{|c|}{k=6}  & -0.4636                        & 0.6435                         & 0.6774                         & 0.6435                         \\ \hline
		\multicolumn{1}{|c|}{k=7}  & -0.2450                        & 0.8622                         & 0.8961                         & 0.8622                         \\ \hline
		\multicolumn{1}{|c|}{k=8}  & 0                              & 1.1071                         & 1.0304                         & 1.0304                         \\ \hline
		\multicolumn{1}{|c|}{k=9}  & 0.4636                         & 1.1071                         & 1.1071                         & 0.9612                         \\ \hline
		\multicolumn{1}{|c|}{k=10} & 0.6435                         & 1.1071                         & 1.1071                         & 0.9991                         \\ \hline
		\multicolumn{1}{|c|}{k=11} & \cellcolor[HTML]{FD6864}0.2450 & 1.0304                         & 1.1071                         & 1.1410                         \\ \hline
		\multicolumn{1}{|c|}{k=12} & 0.7854                         & 1.0304                         & 0.9965                         & 1.0304                         \\ \hline
		\multicolumn{1}{|c|}{k=13} & 1.1071                         & 1.1071                         & 1.1071                         & 1.1410                         \\ \hline
		\multicolumn{1}{|c|}{k=14} & 0.9828                         & 0.9828                         & 1.1071                         & 1.0167                         \\ \hline
		\multicolumn{1}{|c|}{k=15} & 0.8961                         & \cellcolor[HTML]{FD6864}1.1410 & 1.0204                         & \cellcolor[HTML]{FD6864}1.0543 \\ \hline
	\end{tabular}
	\caption{Matriz $\phi$ para o dado Exemplo}
	\vspace{-3.5mm}
	\caption*{Fonte: Autoria Própria}
	\label{tab:TBSExemple}
\end{table}


\subsection{MSR-CORDIC}
\label{section:MSR-CORDIC}

Como pode ser visto na Seção (\ref{sec:CoricTradicional}) o Algoritmo Cordic Tradicional possui a necessidade de realizar a correção do ganho $k_c$ após o processo de rotação do vetor, além de requisitar um número elevado de interações a fim de reduzir o erro de aproximação do vetor. Para reduzir o número de interações Cordic o EEAS aumenta o número de termos SPT, porém acaba por impactar o ganho $K_c$, que passa a não ser mais constante e necessita ser compensado a cada iteração. Tanto no algoritmo tradicional quanto o EEAS a correção final de $K_c$, que se estabelece sempre abaixo da unidade, provoca uma degradação do SQNR.

Segundo \citeonline{Chih} para evitar esta degradação é necessário manter o modulo do vetor de entrada o mais perto da unidade a cada interação. Assim \citeonline{Chih} reformula o algoritmo Cordic para um novo esquema que passa a distribuir os termos SPT de forma diferente do EEAS, afim de dar mais liberdade ao ganho $K_c$ e reduzir o número de interações necessárias para atingir um erro de aproximação admissível. Tal algoritmo pode ser expressado por:

\begin{eqnarray}
	\left[\begin{array}{c}
		x(n+1) \\
		y(n+1) \\
	\end{array}\right]
	\left[\begin{array}{cc}
		\sum_{i=1}^{I} \mu_{i}2^{-s_i (n)} & - \sum_{j=1}^{J} \mu_{j}2^{-s_j (n)}\\
		\sum_{j=1}^{J} \mu_{j}2^{-s_j (n)} & \sum_{i=1}^{I} \mu_{i}2^{-s_i (n)} \\
	\end{array}\right] \left[\begin{array}{c}
			x(n) \\
			y(n) \\
	\end{array}	\right] \label{eq:MSR} \\
	z(n+1)~=~z(n-1)+\theta_n \\
	:~\mu_{i},\mu_{j} \in \{-1,0,1\},~s_i,s_j \in \{0,1, \dots, S\} \\
	:~I + J~=~N_{spt} 
	\label{eq:Nspt}
\end{eqnarray}

A reformulação apresentada por \citeonline{Chih} incrementa termos SPT  nas parcelas $x(n)$ de $x(n+1)$ e $y(n)$ de $y(n+1)$, afim de possibilitar o ganho $K_c$ se tornar maior ou menor do que a unidade, dependendo da escolha dos parâmetros Cordic. Através desta alteração  é possível realizar a operação de microrotação e a compensação do ganho $K_c$ simultaneamente.  Por tais motivos este algoritmo Coridc é denominado de \textit{Mixed Scaling Rotation} (MSR). Consequentemente ao inserir mais termos  na função Coridc, tanto  $\theta_n$ quanto $K_c$ precisam ser corrigidos \cite{Kuo}. Portanto  $\theta_n$ e $K_c$ passam a definidos por:

\begin{equation}
	\theta_n~=~tan^{-1} \left(\frac{\sum_{j=1}^{J} \mu_{j}2^{-s_j (n)}}{\sum_{i=1}^{I} \mu_{i}2^{-s_i (n)}}\right)
	\label{eq:MSRtheta}
\end{equation}

\begin{equation}
	K_n~=~\frac{1}{\sqrt{ \left( \sum_{i=1}^{I} 2^{-s_i (n)}\right)^2 + \left(\sum_{j=1}^{J} 2^{-s_j (n)} \right)^2 } }
	\label{eq:MSRKnc}
\end{equation}

\begin{equation}
	K_c~=~\prod_{n=0}^{N-1} K(n)
	\label{eq:MSRKn}
\end{equation}


Como pode ser percebido em (\ref{eq:MSRKnc}) e (\ref{eq:MSRtheta}), através da escolha adequada dos conjuntos de termos $\mu_i$, $\mu_j$, $S_i$ e $S_j$, e dos valores de $I$ e $J$ é possível aproximar $K_c$ da unidade a cada interação ao mesmo tempo em que o erro $\zeta$ é reduzido. No MSR o conjunto de ângulos elementares  é definidor por:

\begin{eqnarray}
	S_3 = \{ tan^{-1} \left(\frac{\sum_{j=1}^{J} \mu_{j}2^{-s_j (n)}}{\sum_{i=1}^{I} \mu_{i}2^{-s_i (n)}}\right) \} \\ 
	:~\mu_{i},\mu_{j} \in \{-1,0,1\},~s_i,s_j \in \{0,1, \dots, S\} 
	\label{eq:S3}
\end{eqnarray}

E consequentemente o erro $\zeta$ é definido por:

\begin{eqnarray}
	min~\zeta~=~\left| \theta~-~\sum_{n=0}^{N-1}  tan^{-1} \left(\frac{\sum_{j=1}^{J} \mu_{j}2^{-s_j (n)}}{\sum_{i=1}^{I} \mu_{i}2^{-s_i (n)}}\right) \right| \\
	:~\mu_{i},\mu_{j} \in \{-1,0,1\},~s_0,s_1 \in \{0,1, \dots, S\}
	\label{eq:Zeta2}
\end{eqnarray} 

Com mais graus de liberdade o MSR possui uma densidade combinacional dentro do circulo unitário maior do que o CORDIC tradicional e o EEAS-CORDIC \cite{Kuo}, como pode ser visto na Figura (\ref{fig:CordicComparationMSR}).

\vspace{5mm}
\begin{figure}[H]
	\centering
	\captionsetup{width=0.6\textwidth, font=footnotesize, textfont=bf}	
	\includegraphics[width=0.6\linewidth]{Images/RevisaoDeLiteratura/CordicComparationMSR.PNG}
	\caption{MSR com I=2, J=1 e N=2}
	\vspace{-3.5mm}
	\caption*{Fonte: \cite{Chih}}
	\label{fig:CordicComparationMSR}
\end{figure}    
\vspace{5mm}

O incremento de mais termos SPT na definição do ângulo de rotação $\theta_n$ acaba por dar ao conjunto dos ângulos elementares mais liberdade combinacional dentro do circulo unitário. No algoritmo Cordic tradicional e no EEAS havia uma dificuldade de realizar rotações maiores que $\pi / 4$, devido a distribuição  dos ângulos elementares, como pode ser visto nas Figura (\ref{fig:CordicComparationCordic}) e (\ref{fig:CordicComparationEEAS}). Devido a esta dificuldade era necessário realizar uma pré-rotação no vetor de entrada, quando o ângulo de rotação era maior que $\pi / 4$, afim de reduzir o ângulo para uma faixa mais aceitável de rotação. O que aumentava o custo computacional do algoritmo, e demandava mais recursos de \textit{hardware}.

Porém no Algoritmo MSR o conjunto dos ângulos elementares no circulo unitário e maior e melhor distribuídos como visto na Figura (\ref{fig:CordicComparationMSR}). Isto possibilita ao MSR alcançar ângulos de rotação de $0$ á $2 \pi$, varrendo todo o circulo unitário.

O desempenho do algoritmo EEAS, como mostrado na seção anterior, é diretamente relacionado com a escolha dos parâmetros Coridc $\mu_{0}$, $\mu_{1}$, $s_0$ e $s_1$. De maneira análoga é a determinação dos parâmetros Cordic $J$, $I$, $\mu_{i}$, $\mu_{j}$, $s_i$ e $s_j$ que garante a convergência e eficiência do algoritmo. 

Para determinar os parâmetros Cordic do algoritmo MSR, \citeonline{Chih} utiliza a análise do error entre o vetor idealmente rotacionado, e o vetor que na prática do Algoritmo MSR consegue alcançar no rotacionamento. Para exemplificado considere que se deseja rotacionar um vetor $\overline{OD}$ pelo ângulo $\theta$ até a posição do ponto $A$, formando assim um novo vetor rotacionado $\overline{OA}$. Considerando que o MSR não consiga rotacionar o vetor $\overline{OD}$ por exatamente $\theta$, e que devido ao ganho Cordic o módulo do vetor rotacionado seja diferente do vetor $\overline{OD}$. Assim a nova posição do vetor rotacionado seja $\overline{OB}$, como mostrado na Figura (\ref{fig:AnaliseDoErroZeta})\cite{Chih}.

\vspace{5mm}
\begin{figure}[H]
	\centering
	\captionsetup{width=0.45\textwidth, font=footnotesize, textfont=bf}	
	\includegraphics[width=0.45\linewidth]{Images/RevisaoDeLiteratura/AnaliseDoErroZeta.eps}
	\caption{MSR com I=2, J=1 e N=2}
	\vspace{-3.5mm}
	\caption*{Fonte: \cite{Chih}}
	\label{fig:AnaliseDoErroZeta}
\end{figure}    
\vspace{5mm}

Portanto analisando a Figura (\ref{fig:AnaliseDoErroZeta}), o erro de aproximação $\upepsilon$ do algoritmo MSR é representado pelo trecho $\overline{OB}$, denominado $\Delta l'$. Já o erro angular é representado por $\Delta \theta$, e o erro do módulo é representado pelo trecho $\overline{OC}$, denominado $\Delta l'$. Segundo \citeonline{Chih} quando $\Delta \theta$ é suficientemente pequeno é possível obter a seguinte expressão:

\begin{eqnarray}
	\Delta l'^2 ~ = ~ \overline{OA}^2 + \overline{OB}^2 - 2\overline{OA} \times \overline{OB}cos(\Delta \theta) \\
	\Delta l'^2 ~ = ~ 1 + (1 + \Delta l)^2 - 2 \times 1 \times (1+\Delta l) \times \sqrt{1 - sin^2 (\Delta \theta)}\\
	\Delta l'^2 ~ \approx ~ \Delta l^2 + \Delta \theta^2
	\label{eq:AproximacaoDeltal} 
\end{eqnarray}

Por meio da Equação (\ref{eq:AproximacaoDeltal}) é possível concluir que o erro angular $\Delta \theta$, e o erro modular $\Delta l$ possuem o mesmo impacto no erro de aproximação do algoritmo MSR. Portanto afim de otimizar o desempenho do algoritmo MSR é necessário escolher um conjunto de parâmetros Cordic que privilegiem igualmente a redução de ambos os erros de aproximação \cite{Chih}.

Assim determinar o conjunto dos melhores valores para os parâmetros Cordic $J$, $I$, $\mu_{i}$, $\mu_{j}$, $s_i$ e $s_j$ nada mais é do que uma tarefa de otimização, onde a equação de minimização é a expressão do erro $\upepsilon$, o qual pode ser definido como:

\begin{equation}
	min~ \upepsilon~ = ~\sqrt{\Delta l^2 + \Delta \theta^2}
	\label{eq:OtimizacaoMSR}
\end{equation}

Para solucionar esta tarefa de otimização de $\upepsilon$  é possível utilizar diferentes tipos de algoritmos, e inclusive adaptar o algoritmo TBS já apresentado. Segundo \citeonline{Chih} existe uma certa restrição quanto a utilização de algoritmos como o \textit{greedy}, pois este tipo de algoritmo "guloso" não garante a melhor solução dentro do conjunto de soluções possíveis deste problema.

\subsubsection{Análise do Erro}
\label{section:AnaliseDoErro}

Um importante fator para a determinação do melhor conjunto de parâmetros Cordic para o MSR, além da minimização do erro  $\upepsilon$, é o efeito do ruído de arredondamento (\textit{Roundoff Noise Analysis}) $e_n$, e o erro de \textit{overflow}, ou estouro da palavra binária. Ambos os efeitos ocorrem ao longo das operações lógicas promovidas pela algoritmo Cordic, em especial devido a operação de compensação do ganho $K_c$. Esta compensação envolve uma operação de multiplicação, o que acentua os problemas de arredondamento da parte fracionária, e dependendo do valor da compensação pode causar um \textit{overflow} da palavras binária.

Nos dispositivos digitais o número de \textit{bits} utilizados para representar sinais quantizados é limitado de acordo com a arquitetura. Este limite de representação acaba por impactar a resolução da palavra binária para números fracionários, o que força a realização de arrendondamentos na representação binária. 

Para representar o conjunto dos números racionais no mundo digital a arquitetura dos sistemas digitais reserva parte dos \textit{bits} da palavra binária para representar o fracionário do número racional. Assim, segundo \cite{Chih},  os níveis de quantização para um sinal digital são definidos como:

\begin{equation}
	\left\{-2^{W-i-1},...,-2^{-i+1}, -2^{-i}, -2^{-i+1}, ..., 2^{W-i-1} \right\}  
\end{equation}

Onde $W$ representa o numero de \textit{bits} da palavra binária, e $i$ representa o número de dígitos fracionários.

Uma solução simples para reduzir o efeito do $e_n$ é aumentar o número de \textit{bits} $W$ e $i$, melhorando a resolução da representação. Porém esta solução, como afirma \cite{Chih}, provocaria uma redução na velocidade computacional do sistema, e ainda consumiria mais recursos de \textit{hardware}.

Outra opção seria reduzir o número de \textit{bits} utilizados para representar a parte inteira do número, e transferir estes \textit{bits} para a parte fracionária. Porém este método pode provocar um \textit{overflow} da palavra binária, o que é ainda pior do que um ruído de arredondamento.  

Considerando a amplitude $\rho$ de um sinal de entrada, definido entre os intervalos:

\begin{equation}
	-2^{Wa} \leq \rho \leq 2^{W_b} -1,~~para~W_a,W_b \geq 0
\end{equation} 

onde $Wa$ e $Wb$ representam respectivamente o limite superior e inferior da amplitude do módulo deste sinal. E ainda:

\begin{equation}
	W_{max}~=~max\{W_a,W_b\}
\end{equation} 
 
como o limite absoluto deste sinal. O número mínimo de \textit{bits} necessários para representar este sinal seria de $(W_{max}+1)$. Assim, segundo \cite{Chih}, para evitar um \textit{overflow} seria necessário manter o sinal de entrada dentro da seguinte restrição:

\begin{equation}
	2^{W_{max}}~\leq~2^{W-1-i}
\end{equation}

Para solver o problema do ruído de arredondamento, \citeonline{Chih} assume que o $e_n$ é uniformemente distribuído e não possui correlação com outros sinais. Além de considerar que, baseado nos níveis de quantização, o $e_n$ esta situado em uma faixa simétrica de $(-2^{-i-1}, 2^{-i-1})$. Portanto a variância de $e_n$ é dada por:

\begin{equation}
	\sigma_{e_n}^2~=~\frac{V^2_{LSB}}{12}
	\label{eq:variancia}
\end{equation} 

Onde  $V_{LSB}$ é igual a $2^i$. Logo a variância do erro de arredondamento é proporcional ao quadrado valor do ultimo $bit$ da palavra binária. 

Como base na Equação (\ref{eq:variancia}) \citeonline{Chih} analisa o efeito a operação de rotação tem sobre a variância de $e_n$, e mais especificamento o efeito que o ganho $K_c$ tem sobre o SQNR. Quando o ganho $K_c$ é $> ~1$ ou $<~1$ SQNR é reduzido para $1/(K_n)$ a cada interação Cordic.

Assim o ganho $K_C$ é fator importante no projeto dos parâmetros Cordic para o MSR, afetando tanto o erro $e_n$ quanto $\upepsilon$. Assim para refinar a função de minimização apresentada em (\ref{eq:OtimizacaoMSR}), \citeonline{Chih} adiciona a seguinte restrição em relação ao valor do ganho $K_c$:

\begin{equation}
	P_{lower} ~=~1/P_{upper}
\end{equation}

Onde $P_{upper}$ e $P_{lower}$ são respectivamente o limite superior e o limite inferior de $K_n$ a cada interação.

O gráfico da Figura (\ref{fig:RelacaoSQNReKc}) faz uma análise prática entre o nível do SQNR e o $P_{upper}$, para diferentes valores de deslocamento de \textit{bits} ($S$). 

\vspace{5mm}
\begin{figure}[H]
	\centering
	\captionsetup{width=0.9\textwidth, font=footnotesize, textfont=bf}	
	\includegraphics[width=0.9\linewidth]{Images/RevisaoDeLiteratura/RelacaoSQNReKc.pdf}
	\caption{Relação entre o $P_{upper}$ e o SQNR para MSR-CORDIC, como $N_{spt}~=~3$ e $N=3$}
	\vspace{-3.5mm}
	\caption*{Fonte: \cite{Chih}}
	\label{fig:RelacaoSQNReKc}
\end{figure}    
\vspace{5mm}

Por meio desta análise \citeonline{Chih} sugere que para um bom projeto de parâmetros MSR Cordic, onde $N_{spt}~=~3$ e $N=3$, o valor de  $P_{upper}$ deve estar próximo de $1,5$. Já que como pode ser visto na Figura (\ref{fig:RelacaoSQNReKc}), para valores maiores o desempenho de SQNR é saturado. Logo, para este caso, é possível adicionar mais esta restrição a equação de minimização do erro $\epsilon$.

O ultimo aspecto da melhoria do erro $e_n$ é a escola dos parâmetros $I$ e $J$. Estes parâmetros estão diretamente relacionados a $N_{spt}$, o número de termos SPT presentes na equação $x(n+1)$ e $y(n+1)$. Esta relação é descrita pela Equação (\ref{eq:Nspt}). O valor de $N_{spt}$ é uma escolha que impacta na no número de deslocadores de \textit{bits} (\textit{shifters}) necessários para realizar a operação Cordic, sendo mais comum na bibliografia observar implementação MSR Cordic com $N_{spt}=3$ ou $N_{spt}=4$ \cite{Park} \cite{Chih} \cite{Kamal} \cite{Meher}. 

Os valores $I$ e $J$ podem ser escolhidos como fixos (Modo Normal) ou podem ser dinâmicos a cada operação de rotacionamento (Modo Generalizado). Tanto no modo Normal quanto o Generalizado, o valor de $I$ e $J$ devem obedecer a restrição $I+J=N_{SPT}$, porém ao utilizar o modo Normal é possível reduzir a complexabilidade do \textit{hardware} e alcança um desempenho aceitável. Para tal quando em modo de operação Normal os parâmetros deve $I$ e $J$ devem atender a duas restrição dadas a seguir \cite{Chih}:

\begin{itemize}
	\item Se $N_{spt}$ é par: $I~=~J~=~N_{spt}/2$
	\item Se $N_{spt}$ é ímpar: $J~=(N_{spt}+1)/2$ e $I~=~J-1$
\end{itemize}

A operação em modo Generalizado permite que o desempenho do MSR Cordic seja maior, já que nesta configuração as possibilidades combinatórias dos parâmetros Cordic são maiores. Neste modo passa a existir, além da operação normal de rotacionamento, a possibilidade de ocorrer a operação de multiplicação de escala, quando $J=0$, e a operação de inversão de escala, quando $I=0$. Estas operações adicionais maximizam o desempenho nas rotações em ângulos como $\pi/4$, $\pi/2$ e $\pi$. Na prática este modo requer o uso de mais 3 \textit{switch} de controle,o que em muitas aplicações torna viável aumentar o consumo de recursos para alcançar um melhor desempenho. 

Alinhando todas as restrições apresentadas com a equação de minimização apresentada em (\ref{eq:OtimizacaoMSR}), é obtido um conjunto de parâmetros Cordic que otimizam a operação de rotacionamento, elevando o valor de SQNR do sinal.






   
   
  